{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural networks\n",
    "# Perceptron is simplest neural network possible\n",
    "# Consists of one more input and sent to processor to create an output\n",
    "# Receive input, weight input, sum inputs, generate output\n",
    "# Output is generated by passing sum into a activation function to determine if to fire output\n",
    "# Common to put in bias as well to shift to create new boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training perceptrons:\n",
    "# 1. Provide perceptron with inputs for which there is known answer\n",
    "# 2. Ask the perceptron to guess an answer\n",
    "# 3. Compute the error\n",
    "# 4. Adjust all the wieghts according to the error\n",
    "# 5. Return to step 1 and repeat\n",
    "# layer a bunch of perceptrons to create a neural net\n",
    "# input layer -> hidden layer -> output layer\n",
    "# MSFT vision recognition uses 152 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update mnist section\n",
    "\"\"\"\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    " \n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    " \n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    " \n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    " \n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    " \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    " \n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    " \n",
    "sess = tf.InteractiveSession()\n",
    " \n",
    "tf.global_variables_initializer().run()\n",
    " \n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    " \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    " \n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# updated contrib.learn section\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    " \n",
    "# Data sets\n",
    "iris = load_iris()\n",
    "X =np.float32(iris['data']) \n",
    "y = iris['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    " \n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    " \n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"./output\")\n",
    " \n",
    "# Fit model.\n",
    "classifier.fit(X_train, y_train, steps=2000)\n",
    " \n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(X_test, y_test)[\"accuracy\"]\n",
    "print('Accuracy: {0:f}'.format(accuracy_score))\n",
    " \n",
    "#Evaluate with classification report and confusion matrix\n",
    "iris_predictions = list(classifier.predict(X_test))\n",
    "print(classification_report(y_test,  iris_predictions))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,  iris_predictions))\n",
    "print('\\n')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello World'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(2)\n",
    "y = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations with Constants\n",
      "Addition:  5\n",
      "Subtraction:  -1\n",
      "Multiplication:  6\n",
      "Multiplication:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Operations with Constants')\n",
    "    print('Addition: ',sess.run(x+y))\n",
    "    print('Subtraction: ',sess.run(x-y))\n",
    "    print('Multiplication: ',sess.run(x*y))\n",
    "    print('Multiplication: ',sess.run(x/y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32)\n",
    "y = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations\n",
    "add = tf.add(x,y)\n",
    "sub = tf.subtract(x,y)\n",
    "mul = tf.multiply(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations with Placeholders\n",
      "addition 50\n",
      "subtraction -10\n",
      "multiplication 600\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print('Operations with Placeholders')\n",
    "    print('addition',sess.run(add,feed_dict={x:20,y:30}))\n",
    "    print('subtraction',sess.run(sub,feed_dict={x:20,y:30}))\n",
    "    print('multiplication',sess.run(mul,feed_dict={x:20,y:30}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[5.0,5.0,]])\n",
    "b = np.array([[2.0],[2.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = tf.constant(a)\n",
    "mat2 = tf.constant(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_multi = tf.matmul(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(matrix_multi)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanhsu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mnist.train.images[323].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c29efae10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c29d08f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    \"\"\"\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: dict of bias values\n",
    "    \"\"\"\n",
    "    # First Hidden Layer with RELU Activation\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # Func(X * W + B) where Func = RELU -> max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    #Second Hidden Layer\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    #Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None means it can be of any size\n",
    "x = tf.placeholder('float',[None,n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y outputs the actual labels\n",
    "# x inputs the 784 bytes\n",
    "Xsamp,ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-122-28aeef5189f0>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  cost143.5352\n",
      "Epoch: 2  cost36.4594\n",
      "Epoch: 3  cost23.0789\n",
      "Epoch: 4  cost16.0012\n",
      "Epoch: 5  cost11.5376\n",
      "Epoch: 6  cost8.6784\n",
      "Epoch: 7  cost6.4908\n",
      "Epoch: 8  cost4.8825\n",
      "Epoch: 9  cost3.7110\n",
      "Epoch: 10  cost2.7585\n",
      "Epoch: 11  cost2.0914\n",
      "Epoch: 12  cost1.5811\n",
      "Epoch: 13  cost1.1572\n",
      "Epoch: 14  cost0.8874\n",
      "Epoch: 15  cost0.8145\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# 15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    # Cost\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        _,c = sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n",
    "        avg_cost += c/total_batch\n",
    "    print('Epoch: {}  cost{:.4f}'.format(epoch+1,avg_cost))\n",
    "print('Model has completed {} Epochs of training'.format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions,'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist.test.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9482"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images,y:mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TensorFlow iwth Contrib.Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.learn as learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10f7b5e48>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n"
     ]
    }
   ],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    " \n",
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                            hidden_units=[10, 20, 10],\n",
    "                                            n_classes=3,\n",
    "                                            model_dir=\"./output\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-175-790f15dcad6a>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-175-790f15dcad6a>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-175-790f15dcad6a>:1: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From /Users/seanhsu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./output/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.026157, step = 1\n",
      "INFO:tensorflow:global_step/sec: 613.445\n",
      "INFO:tensorflow:loss = 0.43167064, step = 101 (0.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ./output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.07217584.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x10f7b5748>, 'hidden_units': [10, 20, 10], 'feature_columns': (_RealValuedColumn(column_name='', dimension=4, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x10f514b70>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,steps=200,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/seanhsu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:335: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From /Users/seanhsu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:422: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-200\n"
     ]
    }
   ],
   "source": [
    "iris_predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/seanhsu/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:335: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From /Users/seanhsu/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:422: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from ./output/model.ckpt-200\n"
     ]
    }
   ],
   "source": [
    "iris_predictions = list(classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        19\n",
      "          1       0.76      1.00      0.87        13\n",
      "          2       1.00      0.69      0.82        13\n",
      "\n",
      "avg / total       0.93      0.91      0.91        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,list(iris_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
